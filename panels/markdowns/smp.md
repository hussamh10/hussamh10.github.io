# Social Media Platforms
Social media platforms have fundamentally transformed how we seek, consume, and share information. While there is ample research on the role of these platforms in society [1](https://docs.google.com/document/d/1vVAtMCQnz8WVxtSNQev_e1cGmY9rnY96ecYuAj6C548/edit?tab=t.0), there is little consensus on exactly how and why they drive harmful outcomes. My research aims to bridge this gap by developing a mechanistic understanding of these systems to better control their harms.

**Algorithmic Curation & Preference Learning.** One thrust of my work investigates how curation algorithms infer user preferences and subsequently reinforce problematic information patterns. For example, I have studied how Google Search presents ideologically reinforcing results based on query phrasing, and how YouTube learns and amplifies negative, high-arousal emotional preferences.

**Signal Interpretation & Platform Pathology.** More recently, I have focused on how different platforms interpret user signals (opens, likes, follows) to curate feeds. By treating algorithms as "behavioral" agents, we can identify platform-specific pathologies. For example: YouTube prioritizes implicit interest signals (e.g., watch time), leading to a filter bubble effect. Alternatively, Reddit prioritizes explicit network signals (e.g., following a user), leading to an echo chamber effect.

These algorithmic choices have powerful implications for the behaviors of producers and consumers, ultimately shaping downstream societal outcomes.

Other areas of my prior works can be distilled into answer these two questions:
**Q1.** **How do individuals adopt radical ideologies online?**
**Q2.** **How can platform governance be made more effective?**